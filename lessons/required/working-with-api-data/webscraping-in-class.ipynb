{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Web Scraping\n",
    "\n",
    "_Author: Dave Yerrington (SF)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- Revisit how to locate elements on a webpage\n",
    "- Aquire unstructure data from the internet using Beautiful soup.\n",
    "- Discuss limitations associated with simple requests and urllib libraries\n",
    "- Introduce Selenium as a solution, and implement a scraper using selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Guide\n",
    "\n",
    "- [Introduction](#intro)\n",
    "- [Building a web scraper](#building-scraper)\n",
    "- [Retrieving data from the HTML page](#retrieving-data)\n",
    "    - [Retrieving the restaurant names](#retrieving-names)\n",
    "    - [Challenge: Retrieving the restaurant locations](#retrieving-locations)\n",
    "    - [Retrieving the restaurant prices](#retrieving-prices)\n",
    "\n",
    "\n",
    "- [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "## Introduction\n",
    "\n",
    "In this codealong lesson, we'll build a web scraper using requests and BeautifulSoup. We will also explore how to use a headless browser called Selenium.\n",
    "\n",
    "We'll begin by scraping OpenTable's DC listings. We're interested in knowing the restaurant's **name, location, price, and how many people booked it today.**\n",
    "\n",
    "OpenTable provides all of this information on this given page: http://www.opentable.com/washington-dc-restaurant-listings\n",
    "\n",
    "Let's inspect the elements of this page to assure we can find each of the bits of information in which we're interested.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"building-scraper\"></a>\n",
    "## Building a web scraper\n",
    "\n",
    "Now, let's build a web scraper for OpenTable using urllib and Beautiful Soup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import our necessary first packages\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the url we want to visit\n",
    "url = \"http://www.opentable.com/washington-dc-restaurant-listings\"\n",
    "\n",
    "# visit that url, and grab the html of said page\n",
    "html = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, what is in html?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .text returns the request content in Unicode\n",
    "html.text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to convert this html objct into a soup object so we can parse it using python and BS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert this into a soup object\n",
    "soup = BeautifulSoup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"retrieving-data\"></a>\n",
    "### Retrieving data from the HTML page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first find each restaurant name listed on the page we've loaded. How do we find the page location of the restaurant? (Hint: We need to know where in the **HTML** the restaurant element is housed.) In order to find the HTML that renders the restaurant location, we can use Google Chrome's Inspect tool:\n",
    "\n",
    "> http://www.opentable.com/washington-dc-restaurant-listings\n",
    "\n",
    "> 1. Visit the URL above. \n",
    "\n",
    "> 2. Right-click on an element you are interested in, then choose Inspect (in Chrome). \n",
    "\n",
    "> 3. This will open the Developer Tools and show the HTML used to render the selected page element. \n",
    "\n",
    "> Throughout this lesson, we will use this method to find tags associated with elements of the page we want to scrape.\n",
    "\n",
    "See if you can find the restaurant name on the page. Keep in mind there are many restaurants loaded on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the restaurant names\n",
    "soup.find_all(name='span', attrs={'class':'rest-row-name-text'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to always keep in mind the data types that were returned. Note this is a `list`, and we know that immediately by observing the outer square brackets and commas separating each tag.\n",
    "\n",
    "Next, note the elements of the list are `Tag` objects, not strings. (If they were strings, they would be surrounded by quotes.) The Beautiful Soup authors chose to display a `Tag` object visually as a text representation of the tag and its contents. However, being an object, it has many methods that we can call on it. For example, next we will use the `encode_contents()` method to return the tag's contents encoded as a Python string.\n",
    "\n",
    "<a id=\"retrieving-names\"></a>\n",
    "#### Retrieving the restaurant names\n",
    "\n",
    "Now that we found a list of tags containing the restaurant names, let's think how we can loop through them all one-by-one. In the following cell, we'll print out the name (and **only** the clean name, not the rest of the html) of each restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for each element you find, print out the restaurant name\n",
    "for entry in soup.find_all(name='span', attrs={'class':'rest-row-name-text'}):\n",
    "    print(entry.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!\n",
    "\n",
    "<a id=\"retrieving-locations\"></a>\n",
    "#### Challenge: Retrieving the restaurant locations\n",
    "\n",
    "Can you repeat that process for finding the location? For example, barmini by Jose Andres is in the location listed as \"Penn Quarter\" in our search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, see if you can identify the location for all elements -- print it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now print out EACH location for the restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"retrieving-prices\"></a>\n",
    "#### Retrieving the restaurant prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we've figured out the restaurant name and location. Now we need to grab the price (number of dollar signs on a scale of one to four) for each restaurant. We'll follow the same process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print out all prices\n",
    "soup.find_all('div', {'class':'rest-row-pricing'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out EACH number of dollar signs per restaurant\n",
    "# this one is trickier to eliminate the html. Hint: try a nested find\n",
    "for entry in soup.find_all('div', {'class':'rest-row-pricing'}):\n",
    "    print(entry.find('i').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks great, but what if I wanted just the number of dollar signs per restaurant? Can you figure out a way to simply print out the number of dollar signs per restaurant listed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of dollars signs per restaurant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's weird -- an empty set. Did we find the wrong element? What's going on here? Discuss.\n",
    "\n",
    "How can we debug this? Any ideas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manas' example\n",
    "\n",
    "- Let's find out about the candidates at the last Indian election \n",
    "\n",
    "http://myneta.info/LokSabha2019/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this lesson, we used the Beautiful Soup library to locate elements on a website then scrape their text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
